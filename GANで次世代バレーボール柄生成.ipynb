{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MamedenQ/VolleyballDesign/blob/main/GAN%E3%81%A7%E6%AC%A1%E4%B8%96%E4%BB%A3%E3%83%90%E3%83%AC%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%AB%E6%9F%84%E7%94%9F%E6%88%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrNMaNRuPJsy"
      },
      "source": [
        "# 事前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDwHbqk9lC2V"
      },
      "source": [
        "インポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iYqCTLuPH2N"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZvJA0FJpVkq"
      },
      "source": [
        "各種設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06pQJ2LzNdOZ"
      },
      "outputs": [],
      "source": [
        "# シード値設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n",
        "\n",
        "# 潜在変数の領域\n",
        "z_dim = 100\n",
        "\n",
        "# バッチ数\n",
        "batch_size = 64\n",
        "\n",
        "# 画像サイズ\n",
        "img_size = 64\n",
        "\n",
        "# エポック数\n",
        "num_epochs = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAkwqFN_p1sI"
      },
      "source": [
        "使用デバイス確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulCXW9osPVcg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUOo-lCBp-6J"
      },
      "source": [
        "リポジトリクローン、訓練データ展開"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UREt1JB4BcSm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/MamedenQ/VolleyballDesign\n",
        "!unzip VolleyballDesign/data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XerplLxTPb0F"
      },
      "source": [
        "# Generatorの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B5QIgfJub9B"
      },
      "source": [
        "定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwmRtO0bPfKs"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, img_size * 8,\n",
        "                               kernel_size=4, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size * 8),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(img_size * 8, img_size * 4,\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size * 4),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(img_size * 4, img_size * 2,\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size * 2),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(img_size * 2, img_size,\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.last = nn.Sequential(\n",
        "            nn.ConvTranspose2d(img_size, 3, kernel_size=4,\n",
        "                               stride=2, padding=1, bias=False),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.layer1(z)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GImVAqxlQh40"
      },
      "source": [
        "生成、動作確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYuFUUs8Qivo"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "\n",
        "# randnは標準正規分布(平均0, 分散1の正規分布)に従う乱数を取り出す\n",
        "input_z = torch.randn(1, z_dim, 1, 1)\n",
        "\n",
        "# 偽画像を出力\n",
        "fake_imgs = generator(input_z)\n",
        "\n",
        "# 偽画像表示\n",
        "plt.imshow(np.transpose(fake_imgs[0].detach().numpy(), (1, 2, 0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRjeVCNqSAbm"
      },
      "source": [
        "# Discriminatorの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GXvh1nrxWnX"
      },
      "source": [
        "定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tstKQNUOSMiw"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, img_size, kernel_size=4,\n",
        "                      stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(img_size, img_size*2, kernel_size=4,\n",
        "                      stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(img_size*2, img_size*4, kernel_size=4,\n",
        "                      stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(img_size*4, img_size*8, kernel_size=4,\n",
        "                      stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(img_size * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        self.last = nn.Sequential(\n",
        "            nn.Conv2d(img_size*8, 1, kernel_size=4, stride=1,\n",
        "                      padding=0, bias=False),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J9AYg5CU8-8"
      },
      "source": [
        "生成、動作確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz-_F_57U-VV"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator()\n",
        "\n",
        "# 偽画像を生成\n",
        "input_z = torch.randn(1, z_dim, 1, 1)\n",
        "fake_imgs = generator(input_z)\n",
        "\n",
        "# 偽画像をDiscriminatorに入力\n",
        "d_out = discriminator(fake_imgs)\n",
        "\n",
        "# 判定結果発表\n",
        "print(d_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4amOHGyV6jE"
      },
      "source": [
        "# DataLoaderの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCAMDVoOV7wh"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.ImageFolder(root=\"data\",\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.ColorJitter(brightness=(1, 1.3), contrast=(1, 1.2), saturation=(0.8, 1.2)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]))\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(\n",
        "    np.transpose(\n",
        "        vutils.make_grid(real_batch[0].to(device)[:batch_size], padding=2, normalize=True).cpu(),\n",
        "        (1, 2, 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI_1JxhBWJ0Q"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ8pn8jsYx_M"
      },
      "source": [
        "ネットワーク初期化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xms2b6_2WL2y"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcrS_IBgY0vN"
      },
      "source": [
        "学習処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jUDUueiWP9L"
      },
      "outputs": [],
      "source": [
        "t_start = time.time()\n",
        "\n",
        "# 最適化手法の設定\n",
        "g_lr, d_lr = 0.0002, 0.0002\n",
        "beta1, beta2 = 0.5, 0.999\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), g_lr, [beta1, beta2])\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), d_lr, [beta1, beta2])\n",
        "\n",
        "# 誤差関数を定義\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# ネットワークをGPUへ\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "\n",
        "# 訓練モード設定\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "# ネットワークがある程度固定であれば、高速化させる\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# 損失のリスト初期化\n",
        "g_loss_all = []\n",
        "d_loss_all = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    t_epoch_start = time.time()\n",
        "\n",
        "    # epoch内の損失を溜め込むリスト\n",
        "    epoch_g_loss = []\n",
        "    epoch_d_loss = []\n",
        "\n",
        "    for imgs in dataloader:\n",
        "        ##################\n",
        "        # Discriminator学習\n",
        "        ##################\n",
        "\n",
        "        # GPUが使えるならGPUにデータを送る\n",
        "        imgs = imgs[0].to(device)\n",
        "\n",
        "        # 正解ラベルと偽ラベルを作成\n",
        "        # epochの最後のイテレーションはミニバッチの数が少なくなる\n",
        "        cur_batch_size = imgs.size(0)\n",
        "        label_real = torch.full((cur_batch_size,), 1).to(device)\n",
        "        label_fake = torch.full((cur_batch_size,), 0).to(device)\n",
        "\n",
        "        # 真の画像を判定\n",
        "        d_out_real = discriminator(imgs)\n",
        "\n",
        "        # 偽の画像を生成して判定\n",
        "        input_z = torch.randn(cur_batch_size, z_dim).to(device)\n",
        "        input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
        "        fake_imgs = generator(input_z)\n",
        "        d_out_fake = discriminator(fake_imgs)\n",
        "\n",
        "        # 誤差を計算\n",
        "        label_real = label_real.type_as(d_out_real.view(-1))\n",
        "        d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
        "        label_fake = label_fake.type_as(d_out_fake.view(-1))\n",
        "        d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # バックプロパゲーション\n",
        "        g_optimizer.zero_grad()\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        ##################\n",
        "        # Generator学習\n",
        "        ##################\n",
        "\n",
        "        # 偽の画像を生成して判定\n",
        "        input_z = torch.randn(cur_batch_size, z_dim).to(device)\n",
        "        input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
        "        fake_imgs = generator(input_z)\n",
        "        d_out_fake = discriminator(fake_imgs)\n",
        "\n",
        "        last_d_out_fake = d_out_fake\n",
        "\n",
        "        # 誤差を計算\n",
        "        g_loss = criterion(d_out_fake.view(-1), label_real)\n",
        "\n",
        "        # バックプロパゲーション\n",
        "        g_optimizer.zero_grad()\n",
        "        d_optimizer.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        epoch_d_loss.append(d_loss.item())\n",
        "        epoch_g_loss.append(g_loss.item())\n",
        "\n",
        "    g_losses_mean = np.mean(epoch_g_loss)\n",
        "    d_losses_mean = np.mean(epoch_d_loss)\n",
        "    g_loss_all.append(g_losses_mean)\n",
        "    d_loss_all.append(d_losses_mean)\n",
        "\n",
        "    tqdm.write(\"epoch {} || d_loss:{:.4f} g_loss:{:.4f} timer: {:.4f} sec.\".format(\n",
        "        epoch + 1,\n",
        "        d_losses_mean,\n",
        "        g_losses_mean,\n",
        "        time.time() - t_epoch_start))\n",
        "\n",
        "# 損失をグラフ化\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "ax.plot(g_loss_all, label=\"g loss\", marker=\"o\")\n",
        "ax.plot(d_loss_all, label=\"d loss\", marker=\"*\")\n",
        "ax.legend()\n",
        "\n",
        "print(\"finish time:{:.4f} sec.\".format(time.time() - t_start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FACBtbwWgtx"
      },
      "source": [
        "# 画像生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzq8zJzkWbDU"
      },
      "source": [
        "モデル読み込み（学習なしで画像生成する場合）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EEL0yXNudaq"
      },
      "outputs": [],
      "source": [
        "# generator.load_state_dict(torch.load(\"VolleyballDesign/model/generate.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWB-C5d2WdS1"
      },
      "source": [
        "画像生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2p9-VObTryV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Gen Images\")\n",
        "\n",
        "fixed_z = torch.randn(64, z_dim)\n",
        "fixed_z = fixed_z.view(fixed_z.size(0), fixed_z.size(1), 1, 1)\n",
        "\n",
        "generator.eval()\n",
        "fake_img = generator(fixed_z.to(device))\n",
        "\n",
        "plt.imshow(\n",
        "    np.transpose(\n",
        "        vutils.make_grid(fake_img, padding=2, normalize=True).cpu(),\n",
        "        (1, 2, 0)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wrNMaNRuPJsy",
        "XerplLxTPb0F",
        "nRjeVCNqSAbm",
        "s4amOHGyV6jE",
        "MI_1JxhBWJ0Q",
        "_FACBtbwWgtx"
      ],
      "machine_shape": "hm",
      "name": "GANで次世代バレーボール柄生成.ipynb",
      "provenance": [],
      "mount_file_id": "17vQkt0BLLjVh-SnsZD2VKCpbvev8xqkI",
      "authorship_tag": "ABX9TyPb2SgMuESrf+7zJjxvnUlV",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}